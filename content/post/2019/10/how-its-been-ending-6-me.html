+++
tags  = ["letters"]
title = "How It's Been Ending (6) - Me"
date  = "2019-10-06 06:57:27"
+++
<p>身近な性能問題もだんだんと CPU と OS だけ詳しくてもダメな場面が増えており、不安。</p><p>たとえば GPU. かつては GPU を同時に使うタスクは一つか二つ（すなわちアプリ画面の描画と、場合によってはスクリーンの合成）くらいだったのでその描画のコードを書いている人ががんばって速くすればよかった。しかし NN なり画像処理なりで GPU を使う人が増えてくると、複数の GPU タスクを同時実行したくなる。結果として GPU の overload がおこる。</p><p>複数タスクによる overload を解決するには個々のタスクを実装した人ではなく複数タスクのタイミングとかを仲裁するひと、たとえば自分とか OS の人、とかが問題を分析してタイミングを小細工したり (自分) スケジューラをいじったり (OS の人) する。</p><p>しかし Systrace にしろ vmstat にしろ top にしろ GPU のロードはまったく見えない。GPU のタスクを post したり同期を待ったりする CPU 側のカーネルスレッドのアノテーションは見えるから、それで間接的に GPU がなにかしていると理解するしかない。しかしこうした GPU 情報の粒度や正確さはカーネルの提供する CPU の observability とくらべカスみたいなものであまり役に立たない。</p><p>世の中には <a href="https://developer.qualcomm.com/software/snapdragon-profiler">Snapdragon Profiler</a> というのがあり、これが最後の希望。しかしめちゃめちゃ使いにくい。昔使おうとして挫折した。しかもオープンソース側のツールにまったくインテグレートされていない。不便すぎる。その使いにくい GUI に割く開発資源があったら performance counter なりカーネルドライバの API なりを文書化して upstream のツールから見えるようにしてくれ！カーネルはオープンソースにしなくていいから！<del><a href="https://news.ycombinator.com/item?id=19908741">ARM はしてるけど</a>！</del>(野良だった。) なお ARM は ARM で <a href="https://developer.arm.com/tools-and-software/graphics-and-gaming/arm-mobile-studio/components/streamline-performance-analyzer">Mobile Studio</a> という似たような GUI ツールを作っているらしい。はー・・・。</p><p>GPU はまだツールがあるだけマシで、これが <a href="https://en.wikipedia.org/wiki/Image_processor">ISP</a> とかになると完全にお手上げ。ましてヘンな DSP たちときたら。</p><p>あるとき仕事のアプリで誰かが何らかの新機能を flag flip したところ、どうも ISP を酷使しすぎで熱の問題があるらしいとバグの報告がありフラグは再びオフに、という出来事があった。しかし Systrace をみても全然違いがわからない。</p><p>熱の問題は電力消費が原因なので <a href="https://www.msoon.com/online-store">Monsoon</a> で電力をモニタリングすればデバッグできることはできる。そうした電力 sensitive な機能を開発する人や一部の CI インフラはこれをつかってるのだけれど・・・リアルな電力を測るしか性能問題のデバッグをする方法がないとか荒々しすぎませんかね・・・電力読める sysfs の endpoint なんでないの・・・。(2017 年の <a href="https://lwn.net/Articles/721573/">LWN の記事</a>から<a href="http://events17.linuxfoundation.org/sites/events/files/slides/Need_to_Power_Instrument_Linux_Kernel_v4.pdf">同じ不満を訴えるスライド</a>がリンクされいた。)</p><p>一方で OS の中の人からやってくる advisory は相変わらず Systrace と、あとはせいぜい I/O を睨んだ理解にもとづくコメントばかり。アプリの起動みたいに CPU と I/O だけで説明できる問題を追いかけているうちはそれでいいけど、起動したあとはもうだいぶブラックボックスだよ？アプリの中の人がヘマして電話熱くなってもお手上げじゃない？だいじょうぶなの？</p><p>自分は Linux カーネルに詳しくないので、OS の中の人とまともに話ができるくらいは詳しくなりたいという希望がある。一方で、カーネルや CPU の外に熱や性能のボトルネックが生まれつつある。一方で GPU にしても ISP にしても結局アプリとの間にはカーネルが挟まっているので、その理解をさぼると E2E で問題を理解できない。きびしい。</p><p><hr /></p><p>といった動向から身の振り方を考えるに・・・</p><p>短期的には、Snapdragon Profiler はどれだけ出来が悪くてウンザリでも触れたほうが良さそう。こういう残念なツールへの習熟は仕事のための税金として受け入れよう。</p><p>長期的には、それでもいちおう Linux にはもうちょっと詳しくならないとダメだなと思う。<a href="/2019/10/03/becoming-classics/">古典</a>として。サーバ側でも意味のある知識だし、潰しは効くでしょう。</p><p>長期的な課題そのにとして、Out-of-CPU への理解を深める上で今更ながら CUDA を実際に触って見る必要もあるかもしれない。これももはや古典。ほんとはモバイルの GPGPU をさわるほうが身近なんだけど Android の GPGPU は mess すぎ。OpenCL を SDK に入れなかった罪を反省してほしい。TF Lite も Caffe も OpenGL ES とかマジかいなと思う。Vulkan Compute とか冷やかしてみたほうがいいのかなあ・・・。</p><p>より投機的には Cloud の FPGA みたいな方向性もあるけど、自分はそんな最先端じゃなくていいです。</p>

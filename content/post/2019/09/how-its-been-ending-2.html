+++
tags  = ["letters"]
title = "How It's Been Ending (2) - CPU"
date  = "2019-09-14 08:01:56"
+++
<p><a href="/2019/09/14/how-its-been-ending-1/">つづきもの</a>。まず CPU と仲間たちがどうやって Moore's Law を終えたのかを雑に考える。</p><p><h2>PC</h2></p><p>身近なところでまず PC クラスの CPU を考えてみる。あまり良い資料がないなとおもっていたら <a href="https://support.apple.com/specs/macnotebooks">Apple が全製品のスペックをカタログ化しれていたので</a>冷やかす。やはり印象としては同じで、2005 年くらいまではびゅーんと伸びていく。Apple は 2006 年あたりで Mac を Intel に移行して PowerPC に見切りをつけるが、皮肉なことにこのへんで Moore's Law がおわってしまい Intel CPU たいして速くならない。<a href="https://en.wikipedia.org/wiki/Intel_Core_(microarchitecture)">Intel Core</a> とかいってた頃。</p><p><a href="https://support.apple.com/kb/SP36?viewlocale=en_US&amp;locale=en_US">2006 年の初代 Intel Macbook Pro</a> が 2GHz x2 core. <a href="https://support.apple.com/kb/SP794?viewlocale=en_US&amp;locale=en_US">2019 年の最新機種</a>が 2.4 GHz x8 core なのでクロック数は 13 年で 2 割しか増えてない... というのは若干フェアではなく、2019 年のCore i9 は TurboBoost で 5GHz までクロックを釣り上げられるので 2.5 倍増えたと言えないこともない。そしてコア数は 4 倍。（値段は二倍くらい？)</p><p>つまりクロック周波数という Moore's Law Pop Culture の基準では 2 割, TurboBoost とマルチコアを考慮すると 2.5x4  = 10 倍増えた。13 年、ゲーム機に世代分なので昔なら周波数だけで百倍速くなったところで定常周波数は二割、マルチコアと TB あわせても 10 倍。時代がおわった感がある。</p><p>コア数や TurboBoost など色々な条件付きで性能を議論しないといけなくなった事実も Post-Moore 時代の特徴と言える。CPU にしてもたとえば Core Duo は 2MB の L2 cache だったのに対し 2019 の Core i9 は 16MB の L3 cache がある。PC 全体の性能でみると、各種バスは速くなっているし SSD という大きな変化もあった。二割しか速くなってない、というのはまったくフェアでない。13 年のあいだに 100 倍はないけど 3-5 倍くらいは速くなってるような気がする。まったく何の根拠もない主観だけど。</p><p>そういえばここ 20 年くらいの PC における大前提の大きな変化として、主戦場がデスクトップからラップトップにうつった。結果として PC といえども消費電力の影響を受けるようになったし、排熱の要件もタイトになった。結果として単純にコアを増やし続ければ良いというわけにもいかなくなった。</p><p>ラップトップの主流化はいつ起きたのだろうね。個人的には Macbook Pro あたりからラップトップに完全移行した記憶がある。世の中的には Netbook のあとに Ultrabook とかいうのがでてきて、それが普及したようなイメージ。<a href="https://en.wikipedia.org/wiki/Ultrabook">Intel が Ultrabook と言い出したのは 2011 年</a>。Macbook Pro は初代が 2006. まあ 2011 以前にも速くて軽いラップトップは一定程度あって、自分は VAIO Z というのをつかっていた。これは 2004 年らしい。雑にいうと 2005-2010 年の間に段々とそうなった感じだろうか。</p><p><h2>Servers</h2></p><p>サーバサイドの CPU はもともと PC の CPU を定数ファクター速くしたものという印象だったけれども、PC がラップトップ主流化で電力キャップされるに従い給電や排熱に融通しやすいサーバーとの差は大きくなっていったと思う。</p><p>いま見てみたら最高級の <a href="https://www.intel.com/content/www/us/en/products/processors/xeon/scalable/platinum-processors/platinum-9282.html">Xeon は 2.6-3.8GHz x 56 cores</a> らしい。値段はさっぱりわからないが <a href="https://arstechnica.com/gadgets/2019/04/intels-new-assault-on-the-data-center-56-core-xeons-10nm-fpgas-100gig-ethernet/">Arstechnica の記事</a>をみると 36 コアのバージョンですら $10000 かららしいので、$20k - $30k くらいだろうか。消費電力も 400W とかまったくわけがわからない。一つのサーバはこれを 4 つまで挿せるらしいので、そのサーバは 200 コアくらいあるのか。すごいね。</p><p>まあ今どきサーバを買う人なんてほとんどいないわけなので次は EC2 を見てみる。Compute Optimized な <a href="https://aws.amazon.com/ec2/instance-types/c5/">C5 instance</a> は c5.metal というやつで 96 vCPU. TurboBoost で 3.5GHz. 上に書いた上限の半分のコア数のやつくらいまでは売ってることがわかる。(ついでに <a href="https://cloud.google.com/custom-machine-types/">GCE</a> をみると・・・よくわからないが 64 vCPU まで増やせるとある。)</p><p>PC の初代 Macbook Pro と比べるべく 2006 年の Xeon のうち一番値段が高いやつを <a href="https://en.wikipedia.org/wiki/List_of_Intel_Xeon_microprocessors">Wikipedia のリスト</a>からさがしてみると <a href="https://ark.intel.com/content/www/us/en/ark/products/27288/intel-xeon-processor-7140n-16m-cache-3-33-ghz-667-mhz-fsb.html">7140N</a> が $2000. 3.3GHz x2. MBP の Core Duo とコア数は同じ、動作周波数が 8 割増くらい。サーバという単位でみると、たぶんこの Xeon を 4 つくらい挿せるサーバがあったことでしょう。しらんけど。</p><p>13 年の差分をみると、動作周波数は 3.3GHz -&gt; 3.8GHz で 2 割増。コア数が 2 -&gt; 50 で 25 倍。あわせて 30 倍くらい。ラップトップの 10 倍よりは伸びているけれど、値段も 10 倍くらいになってるので正しく比較できてる感じがしない。雑に 2019 年製から $2500 くらいの CPU をさがすと <a href="https://ark.intel.com/content/www/us/en/ark/products/192443/intel-xeon-gold-6240-processor-24-75m-cache-2-60-ghz.html">6240</a> が 2.6-3.9GHz x 18 cores. これだとだいたい 10 倍くらいでラップトップと同じ水準の成長となった。</p><p>つまりサーバの CPU はだいたい PC と同じ経緯を辿っているだが、金とデータセンターの力よくわからん。よくわからん。ででかいコア数を積み増していた。</p><p>なお Intel のサイトにはプロセスの集積度も載っている。2006 年の 7140N が 65nm, 2019 年の 9282 が 14nm. 4 倍、というか面積でいうと 16 倍?  更に 10 年遡った 1995 年の Pentium Pro は <a href="https://en.wikipedia.org/wiki/Pentium_Pro">Wikipedia によれば</a> 500nm くらいっぽいので 1995 -&gt; 2006 は 7.5 (or 60) 倍だった。</p><p>2006 年から 2019 年のあいだにおきたサーバサイドの大きな変化は言うまでもなくクラウド。でもそれが CPU の発展にどういう影響を与えたのか、自分にはよくわからない。$10000 を超える超高級巨大 CPU を作る気になったのは仮想化のおかげだろうから、そういう広い意味で「クラウド」の影響はあるかもしれない。</p><p>クラウド業者のデータセンターは小規模なサーバファームと比べ圧倒的に電力消費にうるさいので、以前と比べ野放図に電力を使えなくなった面はありそう。それがなるべくコア数を増やし集積度をあげるという方向に背中を推したのか、それともでかい CPU を避ける圧力となったのか。まあ結果をみるに前者なのだろうな。</p><p><h2>Mobile</h2></p><p>2006 年にはモバイルは・・・なかった (雑すぎる近似。)</p><p>iPhone よくわかんないので Android. 2008 に <a href="https://en.wikipedia.org/wiki/HTC_Dream">G1</a> がでた。CPU は Qcom の ARM11 で 528MHz x 1 core. ときは流れ 2019 年の <a href="https://en.wikipedia.org/wiki/Samsung_Galaxy_S10">Galaxy S10</a> は Snapdragon 855 で "1x2.84 GHz, 3x2.42 GHz and 4x1.8 GHz".</p><p>動作周波数が 5 倍, ぜんぶのコアをあわせると 30 倍。Moore's Law の期待値 100 倍には届かないにせよ 13 年で 10 倍の PC よりは健闘している。毎年でる電話機の新しいモデルは前の世代より体感できる程度には速くなっているから。その経験則とも一致している。</p><p>この健闘はどこから来るのか、雑に想像してみる。ひとつにはモバイルに流れ込んだ資本の勢いだろう。PC 全盛の時代の ARM ファミリーは Intel に比べたらたいした技術力はなかったろうが、モバイルの隆盛にともない金が流れ込んで相対的な技術的洗練が進み、Intel との距離を縮めた。別の言い方をすると、限界までアーキテクチャ的な無理をしてきた Intel に対し素朴さを保ってきた ARM 勢が、その素朴さ貯金を取り崩して性能を手に入れた。</p><p>もうひとつはバッテリーサイズの巨大化。ラップトップ PC が薄型化によってバッテリーサイズを削られたのに対し、モバイルは画面の巨大化に伴う筐体サイズの増大に助けられ、バッテリーサイズを増やせた。おかげでマルチコア化など性能を電力で買うアプローチを積極的に使えた。</p><p>結果として PC とモバイルの距離は縮まった。性能ポップカルチャーの北極星 Geekbench によれば Macbook Pro 2019 のスコアが <a href="https://browser.geekbench.com/macs/447">6900</a> で Galaxy S10+ が <a href="https://browser.geekbench.com/android_devices/847">2100</a>.  3.3 倍くらい。価格差はもっとある・・・のはいいとして、たとえば G1 と初代 Macbook Pro なんてたぶん 10 倍以上差があったことでしょう。</p><p><h2>GPU</h2></p><p>進歩してるんだろうけれど、よくわからない。すごい雑な印象として、少なくともモバイル CPU くらいのペースでは速くなってるかんじ。Intel CPU ほど終わってしまった印象はない。</p><p>計算の性格上 CPU と違って容赦なく並列度を上げていけるので、並列化に重点を置いて増やしている印象がある。あと AI/Crypto で存在感を増し、かつ Cloud 到来にともないデータセンターの中でバスパワーとかの遠慮なく電力を使えるハイエンド機がでてきたのも高速化に寄与している気がする。</p><p>あと CPU と比低レベルの ISA とかを公開していないぶん互換性の制約がすくないので、回路の非効率は CPU よりすくなく、そのぶん性能の伸びがよい、という面はあるのかもしれない。</p><p>それ以外はターゲット領域の CPU に足並みを揃えて進歩してるのではなかろうか。つまり: よくわからん。</p><p><h2>FPGA, ASIC and Domain Specific Architecture</h2></p><p>サーバや PC の世界ではごく限られた用途のニッチという理解。一方モバイルの SoC は面積の半分以上が CPU および GPU 以外すなわち ISP などの ASIC なので、モバイルにおける Moore's Law の文脈でこいつらの存在感は無視すべきでない。</p><p>が、全然わからん。ビデオの codec などは PC でもモバイルでも CPU (のふつうの命令を処理するところ/AP)以外がやっているわけで、それなりに予算を使っているはずなんだけど。</p><p>TPU, NPU や PVC のような DSA は emerging technologies なんでとくに歴史として振り返るものはない気がする。</p><p><h2>SIMD</h2></p><p>CPU は引き続き AVX や Neon などのメディア処理専用命令を足し続けて動作周波数あたりのスループットの改善を試みた。<a href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions">AVX</a> は最初のバージョンは 2011 年, AVX512 というのが 2016 から入り始めて、じりじり命令を増やしている。2011 以前にも MMX や SSE があった。ARM も昔から NEON があり、AVX512 に対応するものとして <a href="https://developer.arm.com/tools-and-software/server-and-hpc/arm-architecture-tools/documentation/introducing-scalable-vector-extension-sve">SVE</a> というのがあるらしい。</p><p><h2>System</h2></p><p>システム全体でみると、歴史的にはそもそも CPU 以外、つまり IO とかが性能のボトルネックという場面が多かった。それを補填するために CPU はでかいキャッシュを積み続けバスも太くなり、その傾向はおおむね続いているという理解。バスについて考えると、モバイルは SoC なので標準規格に引きずられず自分の都合で色々できる利点がある。データセンター業者も非標準な I/O をつかいがち。</p><p>CPU がもたもたしている間に I/O は高速化をつづけ、ギャップは小さくなっている気がする。ストレージだと SSD や NVM. ネットワークも 1Gbps から 10Gbps, 100Gbps と規格が改善し、<a href="https://aws.amazon.com/blogs/aws/the-floodgates-are-open-increased-network-bandwidth-for-ec2-instances/">AWS もインスタンス間は 25Gbps</a> とかいってる。データセンターについてはクラウドの台頭に伴うこうした著しいシステムレベルの改善が CPU の停滞感を隠してきた印象。</p><p>モバイルも、よくわかってないけど色々進歩してるんじゃないの？そういえば 3G から LTE になったのは大きかったね。これも 10 倍以上 100 倍未満の改善。モバイルじゃないけどいわゆる「ブロードバンド」な帯域は 15 年でどのくらい速くなったのだろう。いまいち調べる方法がわからない。</p><p><h2>Observation</h2></p><p>「なにがおきたのか」という当初の疑問に自答すると:</p><p>まず上に書いたスペックの二点比較だけからは自明ではないが当たり前の事実として、動作周波数上昇の slowdown はいきなり起きたわけではなく、徐々におきた。CPU 業者はあの手この手で slowdown の影響を補填しようとした。</p><p>わかりやすいのがマルチコア。動作周波数の停滞に伴いコア数が増えた。ただ PC やモバイルでは思ったほど増えず、せいぜい 8 コアくらいが現状。サーバ側は 100 コアみたいな勢いのでかい CPU もあるが、値段も消費電力もアホみたいに高いので CPU が期待通りの性能上昇を果たしたと解釈するのは無理がある。どちらかというと昔からある HPC/スパコンみたいなジャンルに Intel が踏み込んでいったと見る方が正しい。</p><p>消費電力の壁から、可変周波数が普及した。Intel は TurboBoost があるし、ARM の一族もふつうにクロック数が上下して最大周波数での可動時間はほんとに短い。動作周波数を下げるだけでなく一部のコアを止めることもできる。</p><p>ARM 家は可変長クロックにくわえ Big.Little のような非対称コアが現れた。Snapdragon 855 にいたっては Prime 1, Gold 3, Silver 4 みたいな三段階構成。</p><p>同一クロックでのスループットを稼ぐ SIMD は昔からあって特に Moore's Law 関係ないのかもしれないけれど、引き続き強化されつづけている。</p><p>システム全体でみると CPU の存在感は相対的に下がり、グラフィクス以外の用途、というか 主に ML のおかげで GPU がもてはやされるようになった。特にデータセンターでは PC 相手には役不足なかんじのでかい GPU も重宝されている。モバイルも同様に GPU の存在感は増しているし、GPU だけでなくメディア用途などの ASIC も SoC の面積予算を多く使っている。</p><p>単純なコンピュートだけでなくシステムレベルでの改善もデータセンターを中心に進んだ。ネットワークもストレージもだいぶ速くなった。15 年のスパンだと 100 倍まではいかないにせよ 10 倍よりは改善している。モバイルにしても LTE がやってきた、今年から来年にかけて 5G がくることになっている。家庭のブロードバンドはよくわからない。</p><p>というわけで...</p><p>CPU の動作周波数停滞は CPU 内外の数多の改善によって覆い隠され、計算機業界全体としてはこの 15 年もひきつづき進歩を実感できた。PC は動作周波数依存のパラダイムから脱しきれずに停滞感があったが、サーバサイドはデータセンターへの集約にともなうアーキテクチャの刷新がシステム全体の性能を高めたし、モバイルは雑魚っぽいところから本気度の高い SoC へと進歩し、デバイスの巨大化によるバッテリ容量の増加もそれを助けた。</p><p>ただし Moore's Law のようなわかりやすく乗っかりやすい単一の指標はもうない。レイヤのあちこちでおこるブレイクスルーをその周辺にいる人々が活用し、産業全体としてなんとなく前にすすんでいるのだろう。</p><p>こうした変化をプログラマやソフトウェア開発チームはどのように受け入れたのか、については別項で。</p>

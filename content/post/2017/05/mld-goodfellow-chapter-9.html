+++
tags  = ["mld"]
title = "MLD: Goodfellow, Chapter 9"
date  = "2017-05-20 05:03:14"
+++
<p><a href="http://www.deeplearningbook.org/contents/convnets.html">Convolutional Networks</a>.</p><p>おもったほど新しい発見はなかった。<a href="https://www.coursera.org/learn/neural-networks">NN4ML</a> で読まされた <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf">LaNet</a> や <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">AlexNet</a> の paper がすごいよく書けていたせいか、既にまあまあよく理解できていたっぽい。CNN って基本的なところはあまり難しくない割に強力で、お得感があるよね。</p><p>とはいえ復習としてはよかったし、理論的な位置づけも補強された。あと Neurosciene との関係についての節は読み物として面白かった。網膜の裏の神経というのはある種の CNN で、それがどんな kernel なのかを調べた人がいる、そしてその kernel によって学習される feature は CNN が学習してる feature と結構似てるんだよ、みたいな。やばい。</p><p>具体的なアーキテクチャの話が全然ないのはやや不満。rapidly moving だから本として記録しても仕方ないから、とかかいてあるけど、一個くらい実例の walk though をやってくれてもいいのにね。</p><p>あと CNN は kernel のサイズが画像サイズと独立だから異なるサイズの画像をつかって learning できるのだよ、みたいな話があって、しかしそんな例みたことないし想像もつかないなと調べてみたら<a href="http://stackoverflow.com/questions/36262860/how-to-use-cnn-to-train-input-data-of-different-size">ちょっと大変そうだった</a>。</p>
